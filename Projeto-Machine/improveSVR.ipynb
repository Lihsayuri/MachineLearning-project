{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text  # Registers the ops.\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I think that students would benefit from learn...\n",
       "1       When a problem is a change you have to let it ...\n",
       "2       Dear, Principal\\n\\nIf u change the school poli...\n",
       "3       The best time in life is when you become yours...\n",
       "4       Small act of kindness can impact in other peop...\n",
       "                              ...                        \n",
       "3906    I believe using cellphones in class for educat...\n",
       "3907    Working alone, students do not have to argue w...\n",
       "3908    \"A problem is a chance for you to do your best...\n",
       "3909    Many people disagree with Albert Schweitzer's ...\n",
       "3910    Do you think that failure is the main thing fo...\n",
       "Name: full_text, Length: 3911, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences = df['full_text']\n",
    "english_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\sayur\\AppData\\Local\\Temp\\tfhub_modules\\2753eecf7067df0f1396141df7f2ee1b1fec3444\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sayur\\OneDrive\\Documentos\\AULAS_SEXTO_SEMESTRE\\MachineLearning-project\\Projeto-Machine\\improveSVR.ipynb CÃ©lula: 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sayur/OneDrive/Documentos/AULAS_SEXTO_SEMESTRE/MachineLearning-project/Projeto-Machine/improveSVR.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hub_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/google/sentence-t5/st5-base/1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sayur/OneDrive/Documentos/AULAS_SEXTO_SEMESTRE/MachineLearning-project/Projeto-Machine/improveSVR.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m encoder \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(hub_url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sayur/OneDrive/Documentos/AULAS_SEXTO_SEMESTRE/MachineLearning-project/Projeto-Machine/improveSVR.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tensor_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sayur/OneDrive/Documentos/AULAS_SEXTO_SEMESTRE/MachineLearning-project/Projeto-Machine/improveSVR.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m nao_terminou \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sayur\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:153\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[0;32m    150\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_training_argument \u001b[39m=\u001b[39m func_has_training_argument(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func)\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sayur\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:449\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 449\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[1;32mc:\\Users\\sayur\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_hub\\module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    103\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload_v2(\n\u001b[0;32m    104\u001b[0m       module_path, tags\u001b[39m=\u001b[39mtags, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_v2(module_path, tags\u001b[39m=\u001b[39;49mtags)\n\u001b[0;32m    107\u001b[0m obj\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m is_hub_module_v1  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\load.py:800\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    799\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 800\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    801\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\load.py:905\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tags, \u001b[39mset\u001b[39m):\n\u001b[0;32m    901\u001b[0m   \u001b[39m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    902\u001b[0m   \u001b[39m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m   tags \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(tags)\n\u001b[0;32m    904\u001b[0m saved_model_proto, debug_info \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 905\u001b[0m     loader_impl\u001b[39m.\u001b[39;49mparse_saved_model_with_debug_info(export_dir))\n\u001b[0;32m    907\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(saved_model_proto\u001b[39m.\u001b[39mmeta_graphs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     saved_model_proto\u001b[39m.\u001b[39mmeta_graphs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mHasField(\u001b[39m\"\u001b[39m\u001b[39mobject_graph_def\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    909\u001b[0m   metrics\u001b[39m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     45\u001b[0m   \u001b[39m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   saved_model \u001b[39m=\u001b[39m parse_saved_model(export_dir)\n\u001b[0;32m     59\u001b[0m   debug_info_path \u001b[39m=\u001b[39m file_io\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m     60\u001b[0m       saved_model_utils\u001b[39m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     61\u001b[0m       constants\u001b[39m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     62\u001b[0m   debug_info \u001b[39m=\u001b[39m graph_debug_info_pb2\u001b[39m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot parse file \u001b[39m\u001b[39m{\u001b[39;00mpath_to_pbtxt\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSavedModel file does not exist at: \u001b[39m\u001b[39m{\u001b[39;00mexport_dir\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msep\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mconstants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[39m}\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconstants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\sayur\\AppData\\Local\\Temp\\tfhub_modules\\2753eecf7067df0f1396141df7f2ee1b1fec3444\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "hub_url = \"https://tfhub.dev/google/sentence-t5/st5-base/1\"\n",
    "\n",
    "encoder = hub.KerasLayer(hub_url)\n",
    "tensor_list = []\n",
    "\n",
    "nao_terminou = True\n",
    "\n",
    "i = 0\n",
    "while nao_terminou:\n",
    "    tensor_list.append(encoder(english_sentences[i:i+1])[0][0])\n",
    "    if i == 3910:\n",
    "        nao_terminou = False\n",
    "    i +=1\n",
    "print(nao_terminou)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = [item.numpy() for item in tensor_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "y_train = df_copy.drop(['full_text', 'text_id'], axis=1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0115cb91dc164f8619f4b3a0cf1fef67ee813edec527bcef6b213b2a07de339e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
